\chapter{Foundations of Image Analysis for Motion Estimation}\label{chap:found_mot_est}

\section{What are keypoints?}
According to Trucco \& Verri (1998) \cite{book} a local keypoint is defined as a local, meaningful, detectable part of an image. In the following, the term keypoint will be used for local keypoint. A keypoint is a local feature of an image, a part with some properties that differentiates it from other parts of the image. By meaningful, they mean that the feature is associated to interesting scene elements such as sharp intensity variations created by the contours of the objects in the scene. To be detectable they state that location algorithms must exist, if not, a keypoint would be of no use.

\section{Detecting Keypoints}
There is a wide variety of keypoint detectors, each with their own way of finding keypoints. There are multiple types of keypoint detectors, some focus on corner detection like Harris, FAST and Shi-Tomasi. SIFT and SURF on the other hand are scale-space detectors. The advantage of corner detectors is that they are quite invariant to view changes, on the other hand, scale changes pose a problem. Scale-space detectors try to detect keypoints on different scales of the image to find scale invariant keypoints


\section{Keypoint Descriptors}
The detection of keypoints is not enough. We need a way to compare these keypoints or rather the image patches around a keypoint and its hypothetical counterpart in the second frame. To do this, we can compare the color or gray values directly, or we can transform them into keypoint descriptors and compare these.\bigskip

Once again, there are lots of different keypoint descriptors that can be divided in continuous and binary keypoint descriptors. A continuous keypoint descriptor is nothing more than a high-dimensional real-valued vector describing the surroundings of the keypoint. While a binary keypoint descriptor is an vector of bits. The use of bits has the advantage that Hamming distance can be used to compare descriptors, which is very efficient. Also, storing binary values is cheaper than real values (using floating point).

An important feature of keypoint descriptors is their robustness, SIFT and SURF (continuous descriptors) for instance are robust to illumination, rotation and scale changes. BRIEF (binary descriptor) on the other hand is only robust to illumination, so illumination and scale changes are a problem when using BRIEF. ORB (binary descriptor) tried to eliminate this shortcoming of BRIEF and is invariant to illumination and rotation.

\section{Oriented FAST and rotated BRIEF (ORB)}\label{sec:orb}
ORB is based on a combination of the FAST keypoint detector and the BRIEF keypoint descriptor. With ORB, Rublee et al. (2011) \cite{6126544} didn't just develop a combination of FAST and BRIEF, but enhanced it with extra features to make it rotation invariant and resistant to noise while maintaining the focus on speed.

\subsection{FAST Keypoint Orientation (oFAST)}
Features from Accelerated Segment Test or FAST, proposed by Rosten \& Drummond \cite{10.1007/11744023_34} is a keypoint detector developed with real-time applications in mind. It has thus, as the name suggest, good speed performance. However, the problem with FAST is that there is no orientation component. This is the first thing added by Rublee et al. (2011) \cite{6126544}.\bigskip

\subsubsection{Features from Accelerated Segment Test (FAST)}
To detect if pixel $p$ is a corner, the pixels on circle with radius $r$ around $p$ are considered, see Figure \ref{fig:fastcircle}. In ORB, $r$ equals 9, which is called FAST-9. The intensity of $p$ is $I_p$. To decide if $p$ is a corner, FAST uses a threshold value $t$. If there exists a set of $n$ (usually 12) contiguous pixels on the circle that are either all brighter than $I_p + t$ or all darker than $I_p - t$, then $p$ is considered a corner.\bigskip

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/fast_circle.jpg}
    \caption{Fast with radius 3}
    \captionsource{Source: \cite{10.1007/11744023_34}}
    \label{fig:fastcircle}
\end{figure}

To make this process even faster, a high-speed test was introduced to eliminate a large number of non-corners. This high-speed test checks only four pixels, the ones on top, bottom, left and right. In Figure \ref{fig:fastcircle} these are pixels 1, 5, 9 and 13. At least three out of four of these pixels have to be either all brighter than $I_p + t$ or all darker than $I_p - t$. If this is not the case, there is no possibility for $p$ to be a corner. If this is the case, the full test will decide whether the $p$ is a corner.\bigskip

The problem with FAST is that it doesn't produce a value to indicate how much of a corner a certain pixel is. To cope with this shortcoming, ORB uses a Harris corner measure \cite{Harris1988ACC} to sort the keypoints detected by the FAST detector. After using FAST with a low threshold value (to ensure at least $N$ keypoints are detected), it sorts the corners based on the Harris measure, leaving only the top $N$ points. As FAST doesn't produce multi-scale features, a scale pyramid is used to calculate FAST features at each level in the pyramid.

\subsubsection{Orientation using Intensity Centroid}
ORB uses Intensity Centroid \cite{ROSIN1999291}, a measure of corner orientation. It uses geometric moments to determine the corner orientation. Rosin defines the momentum as: 
\begin{equation}
    m_{pq} = \sum_{x,y} x^p y^q I(x, y),
\end{equation}
the centroid can then be found by:
\begin{equation}
    C = (\frac{m_{10}}{m_{00}},\frac{m_{01}}{m_{00}}).
\end{equation}
Placing $O$ at the center of the corner, a vector $\Vec{OC}$ can be created, the corner orientation is then:
\begin{equation}
    \theta = \mathrm{atan2}(m_{01}, m_{10})
\end{equation}
where $\mathrm{atan2}(x, y)$ or 2-argument arctangent is defined as the angle in the Euclidean plane, given in radians, between the positive x axis and the ray to the point $(x, y) \neq (0, 0)$ \cite{unknown-author-2022}. \autoref{fig:atan2} shows a graph of this function.\bigskip

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/atan2.png}
    \caption{Graph of $\mathrm{atan2}(x,y)$ over $y/x$}
    \label{fig:atan2}
\end{figure}

ORB improves the rotation invariance even more by making sure that the moments are computed with $x$ and $y$ remaining within a circular region of radius $r$. \cite{6126544} found the patch size to be a fit value for $r$. This means $x$ and $y$ run from $[-r, r]$. $\mid C\mid$ approaching 0 makes the measure become unstable, but this is rarely the case for FAST corners \cite{6126544}.

\subsection{Rotation-Aware BRIEF (rBRIEF)}
We now have keypoints and their orientation, the next step is to compute the descriptor using BRIEF. As stated before, BRIEF is not invariant to rotation, which is why ORB introduced a modification: Rotation-Aware BRIEF.

\subsubsection{Binary Robust Independent Elementary Features (BRIEF)}
BRIEF \cite{10.1007/978-3-642-15561-1_56} uses a small number of pairwise comparisons to classify patches from which it makes a bit vector. They defined the test $\tau$ on patch $\boldsymbol{p}$ like this:
\begin{equation}
    \tau(\boldsymbol{p};\boldsymbol{x},\boldsymbol{y}) := \left\{\begin{array}{ll}
         1\quad : \boldsymbol{p}(\boldsymbol{x}) < \boldsymbol{p}(\boldsymbol{y})\\
         0\quad : \boldsymbol{p}(\boldsymbol{x}) \geq \boldsymbol{p}(\boldsymbol{y})
    \end{array} \right.,
\end{equation}
with $\boldsymbol{p}(\boldsymbol{x})$ the pixel intensity in a smoothed version of $\boldsymbol{p}$ at $\boldsymbol{x} = (u, v)^T$. The BRIEF descriptor is then defined as the $n$-dimensional bitstring
\begin{equation}
    f_n(\boldsymbol{p}) := \sum_{1\leq i\leq n} 2^{i-1}\tau(\boldsymbol{p};\boldsymbol{x},\boldsymbol{y}) .
\end{equation}

Relying on the experiments of \cite{10.1007/978-3-642-15561-1_56}, ORB will use $n = 256$, a Gaussian distribution around the center of the patch and smooth the image using an integral image where each test point is a $5 \times 5$ subwindow of a $31 \times 31$ pixel patch. Based on experimental results in \cite{10.1007/978-3-642-15561-1_56} and their own these showed to be performing well.

\subsubsection{Steered BRIEF}
As stated before, BRIEF is not robust when it comes to in-plane rotations. Even small rotations over a few degrees drops the amount of inliers significantly \cite{6126544}. ORB tackles this problem by introducing Steered BRIEF which steers the BRIEF descriptor according to the orientation of the keypoint. \bigskip

To get to the steered BRIEF operator, a $2\times n$ matrix is defined as follows, $n$ being the amount of binary tests:
\begin{equation}
    \MS = \begin{pmatrix}
    x_1,...,x_n \\
    y_1,...,y_n
    \end{pmatrix}
\end{equation}

The steered version $\MS_\theta$ of $\MS$ is constructed using the rotation matrix $\MR_\theta$, $\theta$ being the orientation of the patch:
\begin{equation}
    \MS_\theta = \MR_\theta \MS
\end{equation}
The steered BRIEF operator is now
\begin{equation}
    g_n(\boldsymbol{p},\theta):=f_n(\boldsymbol{p})\mid(x_i,y_i)\in \MS_\theta
\end{equation}

A lookup table is constructed for values of $\theta = 2k\pi/30, k \in \mathbb{N}_0$. If the keypoint orientation $\theta$ is consistent across views, the correct set of points $\MS_\theta$ will be used to compute the descriptor.

\subsubsection{rBRIEF}
However, the benefit of rotational invariance comes at a price. Rublee et al. (2011) \cite{6126544} noticed a loss of variance and high correlation among the binary tests. To cope with these shortcomings, they developed a learning method to choose a good subset of binary tests. The goal is to have high variance of the bit feature and means close to 0.5, as well as being uncorrelated. To do this, they look at all binary tests.\bigskip

\cite{6126544} proposes the following greedy algorithm to get a set of uncorrelated tests with a mean close to 0.5:
\begin{enumerate}
    \item Run each test  against all training patches.\smallskip
    \item Order the tests by their distance from a mean of 0.5, forming the vector $\vt$.\smallskip
    \item Greedy search:\smallskip
    \begin{enumerate}
        \item Put the first test into the result vector $\vr$ and remove it from $\vt$.\smallskip
        \item Take the next test from $\vt$, and compare it against all tests in $\vr$. If its absolute correlation is greater than a threshold, discard it; else add it to $\vr$.\smallskip
        \item Repeat the previous step until there are 256 tests in R. If there are fewer than 256, raise the threshold and try again.\smallskip
    \end{enumerate}
\end{enumerate}

They showed that this is a good method to ensure high diversity and low correlation between the bit features.\bigskip

Rublee et al.\cite{6126544} is the perfect paper for a more detailed explanation of ORB, along with an evaluation and comparison with SURF and SIFT. 


\section{Matching Keypoints}
As of now, we have a method to find good keypoints in an image and a way to describe the keypoint, a descriptor. To make point-to-point correspondences between the keypoints, we need a way to match them. There are multiple ways to do this.

\subsection{Brute force}
When searching for matches using brute force, all possible keypoints of the second frame are matched with a keypoint from the first set. The best match is then selected for that specific keypoint. There are several distance measures to check how good a certain match is, e.g. L1, L2, Hamming. This is repeated for every keypoint of the first frame until they are all matched with a keypoint from the second frame.

\subsection{Fast Library for Approximate Nearest Neighbors (FLANN)}
FLANN is a library in C++ used for finding the nearest neighbour in a high dimensional space. When looking at a descriptor as a vector in a high dimensional space, finding its nearest neighbour is as good as finding the most similar descriptor and thus finding a good match between keypoints.
