\chapter{Theoretical Background}

% In your case, it could for instance contain the math of camera models, the theory of feature point detection and matching, motion field models, in your case in particular the model of a moving plane, parameterization of motion in terms of rotation matrices and translation vectors, and how they are computed from a set of feature point correspondences 

\section{Keypoint detection}

\subsection{What are keypoints}
According to Trucco \& Verri (1998) \cite{book} a local keypoint is defined as a local, meaningful, detectable part of an image. In the following, the term keypoint will be used for local keypoint. A keypoint is a local feature of an image, a part with some properties that differentiates it from other parts of the image. By meaningful, they mean that the feature is associated to interesting scene elements such as sharp intensity variations created by the contours of the objects in the scene. To be detectable they state that location algorithms must exist, if not, a keypoint would be of no use.

\subsection{Keypoint Detection}
There is a wide variety of keypoint detectors, each with their own way of finding keypoints. The two big categories they can be divided in are corner detectors and scale-space detectors. Examples of corner detectors are Harris, FAST and Shi-Tomasi. SIFT and SURF are examples of scale-space detectors. The advantage of corner detectors is that they are quite invariant to view changes. On the other hand, scale changes pose a problem. Scale-space detectors on the other hand try to detect keypoints on different scales of the image to find scale invariant keypoints

\subsection{Keypoint Description}
The detection of keypoints is not enough. If we want to work with them, we need a way to describe them. Otherwise, there is not way of knowing which keypoint in one image corresponds with which keypoint in another image. To do this, we need keypoint descriptors. Once again, there are lots of different keypoint descriptors that can be divided in continuous and binary keypoint descriptors. A continuous keypoint descriptor is nothing more than a high-dimensional real-valued vector describing the surroundings of the keypoint. While a binary keypoint descriptor is an vector of bits. The use of bits has the advantage that Hamming distance can be used to compare descriptors, which is very efficient. Also, storing binary values is cheaper than real values (using floating point).

An important feature of keypoint descriptors is their robustness, SIFT and SURF (continuous descriptors) for instance are robust to illumination, rotation and scale changes. BRIEF (binary descriptor) on the other hand is only robust to illumination, so illumination and scale changes are a problem when using BRIEF. ORB (binary descriptor) tried to eliminate this shortcoming of BRIEF and is invariant to illumination and rotation.

\section{Oriented FAST and rotated BRIEF (ORB)}
ORB is based on a combination of the FAST keypoint detector and the BRIEF keypoint descriptor. With ORB, Rublee et al. (2011) \cite{6126544} didn't just develop a combination of FAST and BRIEF, but enhanced it with extra features to make it rotation invariant and resistant to noise while maintaining the focus on speed.

\subsection{FAST Keypoint Orientation (oFAST)}
Features from Accelerated Segment Test or FAST, proposed by Rosten \& Drummond \cite{10.1007/11744023_34} is a keypoint detector developed with real-time applications in mind. It has thus, as the name suggest, good speed performance. However, the problem with FAST is that there is no orientation component. This is the first thing added by Rublee et al. (2011) \cite{6126544}.\bigskip

\subsubsection{Features from Accelerated Segment Test (FAST)}
To detect if pixel $p$ is a corner, the pixels on circle with radius $r$ around $p$ are considered, see Figure \ref{fig:fastcircle}. In ORB, $r$ equals 9, which is called FAST-9. The intensity of $p$ is $I_p$. To decide if $p$ is a corner, FAST uses a threshold value $t$. If there exists a set of $n$ (usually 12) contiguous pixels on the circle that are either all brighter than $I_p + t$ or all darker than $I_p - t$, then $p$ is considered a corner.\bigskip

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/fast_circle.jpg}
    \caption{Fast with radius 3}
    \captionsource{Source: \cite{10.1007/11744023_34}}
    \label{fig:fastcircle}
\end{figure}

To make this process even faster, a high-speed test was introduced to eliminate a large number of non-corners. This high-speed test checks only four pixels, the ones on top, bottom, left and right. In Figure \ref{fig:fastcircle} these are pixels 1, 5, 9 and 13. At least three out of four of these pixels have to be either all brighter than $I_p + t$ or all darker than $I_p - t$. If this is not the case, there is no possibility for $p$ to be a corner. If this is the case, the full test will decide whether the $p$ is a corner.\bigskip

The problem with FAST is that it doesn't produce a value to indicate how much of a corner a certain pixel is. To cope with this shortcoming, ORB uses a Harris corner measure \cite{Harris1988ACC} to sort the keypoints detected by the FAST detector. After using FAST with a low threshold value (to ensure at least $N$ keypoints), it sorts the corners based on the Harris measure, leaving only the top $N$ points. As FAST doesn't produce multi-scale features, a scale pyramid is used to calculate FAST features at each level in the pyramid.

\subsubsection{Orientation using Intensity Centroid}
ORB uses Intensity Centroid \cite{ROSIN1999291}, a measure of corner orientation. It uses geometric moments to determine the corner orientation. Rosin defines the momentum as: 
\begin{equation}
    m_{pq} = \sum_{x,y} x^p y^q I(x, y),
\end{equation}
the centroid can then be found by:
\begin{equation}
    C = (\frac{m_{10}}{m_{00}},\frac{m_{01}}{m_{00}}).
\end{equation}
Placing $O$ at the center of the corner, a vector $\Vec{OC}$ can be created, the corner orientation is then:
\begin{equation}
    \theta = atan2(m_{01}, m_{10})
\end{equation}
where atan2(x, y) or 2-argument arctangent is defined as the angle in the Euclidean plane, given in radians, between the positive x axis and the ray to the point $(x, y) \neq (0, 0)$ \cite{unknown-author-2022}.\bigskip

ORB improves the rotation invariance even more by making sure that the moments are computed with $x$ and $y$ remaining within a circular region of radius $r$. \cite{6126544} found the patch size to be a fit value for $r$. This means $x$ and $y$ run from $[-r, r]$. $\mid C\mid$ approaching 0 makes the measure become unstable, but this is rarely the case for FAST corners \cite{6126544}.

\subsection{Rotation-Aware BRIEF (rBRIEF)}
We now have keypoints and their orientation, the next step is to compute the descriptor using BRIEF. As stated before, BRIEF is not invariant to rotation, which is why ORB introduced a modification: Rotation-Aware BRIEF.

\subsubsection{Binary Robust Independent Elementary Features (BRIEF)}
BRIEF \cite{10.1007/978-3-642-15561-1_56} uses a small number of pairwise comparisons to classify patches from which it makes a bit vector. They defined the test $\tau$ on patch $\boldsymbol{p}$ like this:
\begin{equation}
    \tau(\boldsymbol{p};\boldsymbol{x},\boldsymbol{y}) := \left\{\begin{array}{ll}
         1\quad : \boldsymbol{p}(\boldsymbol{x}) < \boldsymbol{p}(\boldsymbol{y})\\
         0\quad : \boldsymbol{p}(\boldsymbol{x}) \geq \boldsymbol{p}(\boldsymbol{y})
    \end{array} \right.,
\end{equation}
with $\boldsymbol{p}(\boldsymbol{x})$ the pixel intensity in a smoothed version of $\boldsymbol{p}$ at $\boldsymbol{x} = (u, v)^T$. The BRIEF descriptor is then defined as the $n$-dimensional bitstring
\begin{equation}
    f_n(\boldsymbol{p}) := \sum_{1\leq i\leq n} 2^{i-1}\tau(\boldsymbol{p};\boldsymbol{x},\boldsymbol{y}) .
\end{equation}

Relying on the experiments of \cite{10.1007/978-3-642-15561-1_56}, ORB will use $n = 256$, a Gaussian distribution around the center of the patch and smooth the image using an integral image where each test point is a $5 \times 5$ subwindow of a $31 \times 31$ pixel patch. Based on experimental results in \cite{10.1007/978-3-642-15561-1_56} and their own these showed to be performing well.

\subsubsection{Steered BRIEF}
As stated before, BRIEF is not robust when it comes to in-plane rotations. Even small rotations over a few degrees drops the amount of inliers significantly \cite{6126544}. ORB tackles this problem by introducing Steered BRIEF which steers the BRIEF descriptor according to the orientation of the keypoint. \bigskip

To get to the steered BRIEF operator, a $2\times n$ matrix is defined as follows:
\begin{equation}
    \MS = \begin{pmatrix}
    x_1,...,x_n \\
    y_1,...,y_n
    \end{pmatrix}
\end{equation}

The steered version $\MS_\theta$ of $\MS$ is constructed using the rotation matrix $\MR_\theta$, $\theta$ being the orientation of the patch:
\begin{equation}
    \MS_\theta = \MR_\theta \MS
\end{equation}
The steered BRIEF operator is now
\begin{equation}
    g_n(\boldsymbol{p},\theta):=f_n(\boldsymbol{p})\mid(x_i,y_i)\in \MS_\theta
\end{equation}

A lookup table is constructed for values of $\theta = 2k\pi/30, k \in \mathbb{N}_0$. If the keypoint orientation $\theta$ is consistent across views, the correct set of points $\MS_\theta$ will be used to compute the descriptor.

\subsubsection{rBRIEF}
However, the benefit of rotational invariance comes at a price. \cite{6126544} noticed a loss of variance and high correlation among the binary tests. To cope with these shortcomings, they developed a learning method to choose a good subset of binary tests. The goal is to have high variance and means close to 0.5, as well as being uncorrelated. To do this, they look at all binary tests.\bigskip

\cite{6126544} proposes the following greedy algorithm to get a set of uncorrelated tests with a mean close to 0.5:
\begin{enumerate}
    \item Run each test  against all training patches.\smallskip
    \item Order the tests by their distance from a mean of 0.5, forming the vector $\vt$.\smallskip
    \item Greedy search:\smallskip
    \begin{enumerate}
        \item Put the first test into the result vector $\vr$ and remove it from $\vt$.\smallskip
        \item Take the next test from $\vt$, and compare it against all tests in $\vr$. If its absolute correlation is greater than a threshold, discard it; else add it to $\vr$.\smallskip
        \item Repeat the previous step until there are 256 tests in R. If there are fewer than 256, raise the threshold and try again.\smallskip
    \end{enumerate}
\end{enumerate}

They showed that this is a good method to ensure high diversity and low correlation.\bigskip

Rublee et al.\cite{6126544} is the perfect paper for a more detailed explanation of ORB, along with an evaluation and comparison with SURF and SIFT. 

% \section{Visual Odometry}
% Visual Odometry (VO) is a process that calculates the motion (rotation and translation) of a body based on the images of a single or multiple cameras attached to the body. There are multiple ways to achieve this. 

\section{Camera model}
As we work with 2-D images that are a representation of a 3-D world, there are some things to be said about the projection from 3-D to 2-D. The camera used and it's properties are important factors in determining motion.

\subsection{Pinhole camera model}
\autoref{fig:cammodel} shows the pinhole camera model. $C$ is the perspective center of the camera, the plane $E$ is the plane on which the 3-D world is projected upon. $H$ is called the principal point, it's the perpendicular projection of $C$ onto $E$, this axis is called the optical axis. $f$ is a constant based on the properties of the camera. 

Take point $P$ in the 3-D world, it's coordinates in the can be described with respect to camera coordinate frame with $C$ as its center. When a picture is taken, the $P$ is projected on $E$ resulting in point $p$. $P$ with coordinates $X$, $Y$ and $Z$ is transformed to $p$ with coordinates $x$, $y$ and $z$. $z$ always equals $f$ as axis $Y_3$ is perpendicular to $E$.

We need a way to describe the relationship between $P$ and $p$, the transformation between camera coordinates and image coordinates.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/camera_model.jpg}
    \caption{Pinhole camera model}
    \label{fig:cammodel}
\end{figure}

\section{Motion estimation}
Now that keypoints are detected and matched, the relation between these keypoints can be expressed as a Homography. The Homography is the transformation between the planes in the respective frames. Suppose we have keypoint $\MX = [X_1, X_2, X_3]^T$ that has been matched to keypoint $\MX' = [X_1', X_2', X_3']^T$. The movement of this keypoint can be described as follows: 

\begin{equation} \label{eq:1}
    \begin{pmatrix}
        X_1' \\
        X_2' \\
        X_3'
    \end{pmatrix}
    = \MR
    \begin{pmatrix}
        X_1 \\
        X_2 \\
        X_3
    \end{pmatrix}
    + \vt
\end{equation}
where $\MR$ is a $3 \times 3$ matrix describing the rotation and $\vt$ a vector describing the translation. Also valid is this: 
\begin{equation}
    \begin{pmatrix}
        X_1' \\
        X_2' \\
        X_3'
    \end{pmatrix}
    = \MH
    \begin{pmatrix}
        X_1 \\
        X_2 \\
        X_3
    \end{pmatrix}.
\end{equation} 

So it is clear that there is a relation between $\MH$ on the one hand and $\MR$ and $\vt$ on the other hand.\bigskip

\subsection{Essential matrix}
OpenCV has a method \textit{findHomography} to find this Homography based on the keypoints detected and matched. We need to use this homography to compute rotation-matrix $\MR$ and translation-vector $\vt$. In \cite{improc} T. S. Huang proposed that with at least eight keypoint matches a two-step linear algorithm can be developed. To do this, intermediate values called essential parameters need to be estimated first. These essential parameters form a matrix $\ME$ called the essential matrix:
\begin{equation}
    \ME = 
    \begin{pmatrix}
        e_1&e_2&e_3 \\
        e_4&e_5&e_6 \\
        e_7&e_8&e_9 
    \end{pmatrix}
    = \begin{pmatrix}
        0&-T_3&T_2 \\
        T_3&0&-T_1 \\
        -T_2&T_1&0
    \end{pmatrix}
     \MR
\end{equation}

These nine essential elements are not all independent due to the fact that  $\ME$ is a product of a skew-symmetric matrix and a rotation matrix.\bigskip

\cite{tekalp} states that vectors $\MX'$, $\vt$ and $\MR\MX$ are coplanar, since $\MX' = \MR\MX + \vt$ from (\ref{eq:1}). So now we have 
\begin{equation}
    \MX \cdot (\vt \times \MR\MX) = 0
\end{equation}
because $(\vt \times \MR\MX$ is orthogonal to this plane. From this, it follows that 
\begin{equation} \label{eq:2}
    \MX'^T\ME\MX = 0
\end{equation}

We want to obtain a relationship in terms of the image plane coordinates. To do this, we divide both sides of \ref{eq:2} by $X_3 X'_3$:
\begin{equation} \label{eq:essential}
    \begin{pmatrix}
        x_1'&x_2&1
    \end{pmatrix}
    \ME
    \begin{pmatrix}
        x1 \\
        x2 \\
        1
    \end{pmatrix}
    = 0
\end{equation}

This linear homogeneous equation, in terms of the nine essential parameters, has either no solution or infinitely many solutions. By setting one of these nine essential parameters to one in the equation above, we can solve it for the remaining eight essential parameters. The essential parameter set to one is used as a scale factor. It's important to note that because of scale ambiguity in perspective projection, translation can only be estimated up to a scale factor.

\subsection{Estimation of the Essential Parameters}
To estimate these essential parameters, \cite{tekalp} proposes three methods: a linear lest squares method, an optimisation method requiring at least eight keypoint matches and a nonlinear method where only five, six or seven keypoint matches are needed. We'll discuss the Linear Least Squares Method.\bigskip

As stated before, one of the essential parameters will be set to one. Take $e_9 = 1$, then equation (\ref{eq:essential}) can be written as:
\begin{equation}
    \begin{pmatrix}
        x_1'x_1 &
        x_1'x_2 &
        x_1' &
        x_2'x_1 &
        x_2'x_2 &
        x_2' &
        x_1 &
        x_2
    \end{pmatrix}
    \begin{pmatrix}
        e1 \\
        e2 \\
        e3 \\
        e4 \\
        e5 \\
        e6 \\
        e7 \\
        e8 \\
    \end{pmatrix}
    = -1
\end{equation}

This linear equation in eight essential parameters can be set up as a system of $N$ linear equations in 8 unknowns. To solve this, we need at least $N \geq 8$ keypoint matches. The solution of this equation gives the essential matrix $\ME$ up to a scale factor (as discussed before). We took $e_9$ as the scale factor, but all of the other essential parameters could have been chosen as well. When using this method, $e_i, i = 1,...,9$ will be chosen based on the condition number, the $e_i$ that yields the smallest condition number will be chosen as scale factor.

To have a solution for this equation, the coefficient matrix needs to have full rank, \cite{tekalp} states that this is the case if $\vt \neq 0$ and the shape of the 3-D surface satisfies certain conditions, called the surface constraint.

Other methods to estimate the essential parameters can be found in \cite{tekalp}.

\subsection{Decomposition of the Essential Matrix}
Now that we have the essential parameters that make up the essential matrix $\ME$, we can use this to compute rotation matrix $\MR$ and translation vector $\vt$. To do this, we rewrite $\ME$ as 

\begin{equation} \label{eq:essential2}
    \ME = 
    \begin{pmatrix}
        e1 \mid e2 \mid e3
    \end{pmatrix} = 
    \begin{pmatrix}
        k \hat{t} \times \boldsymbol{r_1} \mid
        k \hat{t} \times \boldsymbol{r_2} \mid
        k \hat{t} \times \boldsymbol{r_3} 
    \end{pmatrix}
\end{equation}

with $\boldsymbol{r_i}, i = 1, 2, 3$ are the columns of rotation matrix $\MR$, $\hat{t}$ and $k$ are the unit vector along and the length of $\vt$ respectively. \cite{tekalp} proposes a method to calculate $\MR$ and  $\hat{t}$ from noise-free as well as a method for noisy point correspondence data. As we strive to have noise-free data, we'll discuss only the first method. For the full step by step mathematical explanation, we refer to \cite{tekalp}. Here we will limit ourselves to the essential steps.\bigskip

By looking at \autoref{eq:essential2}, it is clear that each column of $\ME$ is orthogonal to $\vt$. By taking the cross product of two of the three columns, the unit vector along $\vt$ can be calculated:
\begin{equation}
    \hat{t} = \pm \frac{\boldsymbol{e_i \times e_j}}{\mid\mid e_i \times e_j\mid\mid}
    \quad i \neq j
\end{equation}

The sign of the unit vector can't be calculated with the equation above. Zhuang \cite{ZHUANG1989175} proposed the following to do so:
\begin{equation}
    \sum\begin{pmatrix}
        \hat{t} \times \begin{pmatrix}
            x_1' & x_2' & 1
        \end{pmatrix}^T
    \end{pmatrix}^T
    \cdot \ME\begin{pmatrix}
        x_1 & x_2 & 1
    \end{pmatrix}^T
    > 0
\end{equation}
the summation is taken over all observed keypoint matches.\bigskip

T. S. Huang \cite{improc} showed that 
\begin{equation}
    k^2 = \frac{1}{2}(\boldsymbol{e_1}\cdot\boldsymbol{e_1} + \boldsymbol{e_2}\cdot\boldsymbol{e_2} + \boldsymbol{e_3}\cdot\boldsymbol{e_3})
\end{equation}
Calculating $k$ this way doesn't solve the problem we had with the scale as $\boldsymbol{e_3}$ contains an arbitrary parameter but to determine the rotation parameters, we need this value for $k$.\bigskip

To calculate $\boldsymbol{r_1}$ we first calculate $\boldsymbol{e_2 \times e_3}$:
\begin{align*}
    \boldsymbol{e_2} \times \boldsymbol{e_3} = [(k\hat{t}\times \boldsymbol{r_2})\cdot\boldsymbol{r_3}]k\hat{t} - [(k \hat{t} \times \boldsymbol{r_2})k \hat{t}]\boldsymbol{r_3}
\end{align*}
The first term can be simplified as 
\begin{align}
    [(\boldsymbol{r_2}\times\boldsymbol{r_3})\cdot k\hat{t}]k\hat{t} = (\boldsymbol{r_1}\cdot k\hat{t})k\hat{t}
\end{align}
because $\boldsymbol{r_1}$, $\boldsymbol{r_2}$ and $\boldsymbol{r_3}$ are mutually orthogonal and have unity length. Since $(k\hat{t}\times\boldsymbol{r_2})$ is orthogonal to $k\hat{t}$, the second term is zero. So we have the following equations (\autoref{eq:r2} and \autoref{eq:r3} can be calculated in an analogous way):
\begin{equation}
    \boldsymbol{e_2} \times \boldsymbol{e_3} = k\hat{t}(k\hat{t}\cdot\boldsymbol{r_1})
\end{equation}
\begin{equation}\label{eq:r2}
    \boldsymbol{e_3} \times \boldsymbol{e_1} = k\hat{t}(k\hat{t}\cdot\boldsymbol{r_2})
\end{equation}
\begin{equation}\label{eq:r3}
    \boldsymbol{e_1} \times \boldsymbol{e_2} = k\hat{t}(k\hat{t}\cdot\boldsymbol{r_3})
\end{equation}

By solving these equations to $\boldsymbol{r_1}$, $\boldsymbol{r_2}$ and $\boldsymbol{r_3}$ we get the following equations:
\begin{equation}
    \boldsymbol{r_1} = \biggl[\frac{1}{k^2}\hat{t}\cdot(\boldsymbol{e_2}\times\boldsymbol{e_3})\biggr]\hat{t}+\frac{1}{k}(\boldsymbol{e_1}\times\hat{t})
\end{equation}
\begin{equation}
    \boldsymbol{r_2} = \biggl[\frac{1}{k^2}\hat{t}\cdot(\boldsymbol{e_3}\times\boldsymbol{e_1})\biggr]\hat{t}+\frac{1}{k}(\boldsymbol{e_2}\times\hat{t})
\end{equation}
\begin{equation}
    \boldsymbol{r_2} = \biggl[\frac{1}{k^2}\hat{t}\cdot(\boldsymbol{e_1}\times\boldsymbol{e_2})\biggr]\hat{t}+\frac{1}{k}(\boldsymbol{e_3}\times\hat{t})
\end{equation}\bigskip

\subsection{Homography}

However, the use of essential matrix $\ME$ is too general. When all keypoints lie on a planar surface, we can treat it differently and us Homography $\MH$. As we only look at the points below the horizon, all keypoints lie on a plane that can be described as
\begin{equation}
    aX_1 + bX_2 + cX_3 = 1
\end{equation}
where $(a, b, c)^T$ is the normal vector of this plane. \autoref{eq:1} can then be rewritten as 
\begin{equation}
    \begin{pmatrix}
        X_1' \\
        X_2' \\
        X_3'
    \end{pmatrix} = \MR
    \begin{pmatrix}
        X_1 \\
        X_2 \\
        X_3
    \end{pmatrix} + \vt
    \begin{pmatrix}
        a & b & c
    \end{pmatrix}
    \begin{pmatrix}
        X_1 \\
        X_2 \\
        X_3
    \end{pmatrix}
\end{equation}
or
\begin{equation}
    \begin{pmatrix}
        X_1' \\
        X_2' \\
        X_3'
    \end{pmatrix} =
    \begin{pmatrix}
        a_1 & a_2 & a_3 \\
        a_4 & a_5 & a_6 \\
        a_7 & a_8 & a_9 \\
    \end{pmatrix}
    \begin{pmatrix}
        X_1 \\
        X_2 \\
        X_3
    \end{pmatrix} = \MA
    \begin{pmatrix}
        X_1 \\
        X_2 \\
        X_3
    \end{pmatrix}
\end{equation}
with
\begin{equation} \label{eq:matrixA}
    \MA = \MR + \vt
    \begin{pmatrix}
        a & b & c
    \end{pmatrix}
\end{equation}

$a_1,...,a_9$ are called the pure parameters \cite{506592e3b5484e57928e215df49a83cb}. As with the computation of the essential parameters, the scale ambiguity problem is also present here so we normalise $a_9 = 1$. The 3-D displacement is projected onto a 2-D plane using the perspective transformation. The mapping of 3-D displacement $t$ to 2-D image plane $t'$ is given by 
\begin{equation*}
    x_1' = \frac{a_1x_1 + a_2x_2 + a_3}{a_7x_1 + a_8x_2 + 1}
\end{equation*}
\begin{equation}\label{eq:pure}
     x_2' = \frac{a_4x_1 + a_5x_2 + a_6}{a_7x_1 + a_8x_2 + 1}
\end{equation}

\subsection{Estimation of the pure parameters}
\autoref{eq:pure} can be rearranged by cross-multiplying the equations for each keypoint match:
\begin{equation}
    \begin{pmatrix}
        x_1 & x_2 & 1 & 0 & 0 & 0 & -x_1x_1' & -x_2x_1' \\
        0 & 0 & 0 & x_1 & x_2 & 1 & -x_1x_2' & -x_2x_2'
    \end{pmatrix}
    \begin{pmatrix}
        a_1 \\ a_2 \\ a_3 \\ a_4 \\ a_5 \\ a_6 \\ a_7 \\ a_8 \\
    \end{pmatrix} = 
    \begin{pmatrix}
        x_1' \\ x_2'
    \end{pmatrix}
\end{equation}
So if we have at least four keypoint matches, eight or more linear equations can be set up to solve for the pure parameters. \cite{improc} showed that the rank of the matrix is 8 if and only if no three of the four observed points are collinear in three dimensions.

\subsection{Estimation of the motion and structure parameters}
We now have found the pure parameters and thus matrix $\MA$. As \autoref{eq:matrixA} states, motion parameters $\MR$ and $\vt$ can be derived from $\MA$, as well as the normal vector $(a,b,c)^T$. To do this, we need to decompose $\MA$ using singular value decomposition (SVD). \cite{Huang:86} describes describes a method to do this:

First of all, we write matrix $\MA$ as 
\begin{equation}
    \MA = \MU
    \begin{pmatrix}
        \lambda_1 & 0 & 0 \\
        0 & \lambda_2 & 0 \\
        0 & 0 & \lambda_3
    \end{pmatrix}\MV^T
\end{equation}

where $\MU = (\boldsymbol{u_1}\mid\boldsymbol{u_2}\mid\boldsymbol{u_3})$ and $\MV = (\boldsymbol{v_1}\mid\boldsymbol{v_2}\mid\boldsymbol{v_3})$ are $3\times 3$ orthogonal matrices and $\lambda_1\geq\lambda_2\geq\lambda_3\geq 0$ are the singular values of $\MA$. Depending on the multiplicity of the singular values there are 3 different cases.

\subsubsection{Multiplicity of singular values is 1: $\lambda_1 > \lambda_2 > \lambda_3$}

This indicates that the motion can be decomposed into a rotation around an axis through the origin and a translation in a direction, not along the normal vector. In this case, there are two possible solutions for the pure parameters:
\begin{equation*}
    \MR = \MU
    \begin{pmatrix}
        \alpha & 0 & \beta \\
        0 & 1 & 0 \\
        -s\beta & 0 & s\alpha
    \end{pmatrix}
    \MV^T
\end{equation*}
\begin{equation*}
    \vt = k\biggl(-\beta\boldsymbol{u_1} + (\frac{\lambda_3}{\lambda_2}-s\alpha)\boldsymbol{u_3}\biggr)
\end{equation*}
\begin{equation*}
    \begin{pmatrix}
        a & b & c
    \end{pmatrix}^T = \frac{1}{k}(\delta\boldsymbol{v_1} + \boldsymbol{v_3})
\end{equation*}
with
\begin{equation*}
    \alpha = \frac{\lambda_1 + s\lambda_3\delta^2}{\lambda_2(1+\delta^2)}
\end{equation*}
\begin{equation*}
    \beta = \frac{1}{\delta}\biggl(\alpha-\frac{\lambda_1}{\lambda_2}\biggr)
\end{equation*}
\begin{equation*}
    \delta = \pm\biggl(\frac{\lambda_1^2-\lambda_2^2}{\lambda_2^2-\lambda_3^2}\biggr)^\frac{1}{2}
\end{equation*}
\begin{equation*}
    s = det(\MU) det(\MV)
\end{equation*}
and $k$ is an arbitrary scale factor (either positive or negative). To resolve the scale ambiguity, $1/X_3 > 0$ is required for all points.

\subsubsection{Multiplicity of singular values is 2: $\lambda_1 = \lambda_2 \neq \lambda_3$}
This indicates that the motion can be decomposed into a rotation around an axis through the origin and a translation along the normal vector. Now a unique solution for the motion parameters exist:
\begin{equation*}
    \MR = \frac{1}{\lambda_1}\MA-\biggl(\frac{\lambda_3}{\lambda_1}-s\biggr)\boldsymbol{u_3}\boldsymbol{v_3^T}
\end{equation*}
\begin{equation*}
    \vt = k\biggl(\frac{\lambda_3}{\lambda_1}-s\biggr)
\end{equation*}
\begin{equation*}
    \begin{pmatrix}
        a & b & c
    \end{pmatrix}^T = \frac{1}{k}\boldsymbol{v_3}
\end{equation*}
\begin{equation*}
    s = det(\MU) det(\MV)
\end{equation*}
Once again, $k$ is an arbitrary scale factor.
\subsubsection{Multiplicity of singular values is 2: $\lambda_1 = \lambda_2 = \lambda_3$}
This indicates the rotation is a pure rotation around an axis through the origin. Once again, there's a unique solution for the rotation matrix:
\begin{equation*}
    \MR = (\frac{1}{\lambda_1})\MA
\end{equation*}
In this case, it is not possible to determine translation vector $\vt$ and the normal vector $(a, b, c)^T$ as there is no translation.
