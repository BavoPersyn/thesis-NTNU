\chapter{Report}

\section{Objective of thesis}
\subsection{Primary objectives}
The goal of this master thesis is to build a software system, using computer vision algorithms. First of all, it should be able to estimate the frame-to-frame motion of a racing car and the momentary orientation of the camera with respect to the ground plane. Secondly, at any time, the system should be able to create a birds eye view map of the environment that is in front of the car, in particular the positions of the cones which are used to mark the drivable path.\bigskip 

\subsection{Secondary objectives}
When a good solution is found to these two problems, the system could be expanded and obstacles, side barriers etc. could be entered into the map previously mentioned. Based on the previous features of the system, two additional features could be added: reconstruction of the car's trajectory over time and building a global map from the instantaneous map.\bigskip

These last two additional features are a nice addition to the primal goals, but will only be investigated once the primal goals are working properly.

\section{Sequencer}
First, we need a way to step through the footage of the race car efficiently. For this purpose, a sequencer is built, this sequencer takes footage from a camera mounted to a racing car. The footage from the camera is a video, to process this, each frame of the video is stored as a separate image. These images can be fed to the sequencer to display them. The sequencer stores a predefined amount of images in a buffer and displays the first image in the buffer. With specific keys, it is possible to go forwards and backwards through the sequence. When advancing through the sequence, the next image is displayed and a new image is loaded in the buffer. This buffer works in FIFO style, Going backwards through the buffer is analogous. It is also possible to jump multiple frames ahead/backwards. The buffer is then cleared and filled with the correct images. With a press of the space bar, the sequence continuously shows the next image like a video.

\section{Preprocessing}
\subsection{Grayscale or color}
For now, the images are loaded in grayscale. The big advantage is that a grayscale image only has one third of the information of an image in color with the same dimensions. Computationally everything will be faster using grayscale instead of color images. The drawback is a loss of information, but that drawback is rather small. The color of the image doesn't give us much more information to recognise structure and detect keypoints. So it's not worth the extra computations.\bigskip

However, in the footage we're using, the road is marked by colored cones. Most of the time the road is marked by yellow cones but sometimes there are blue cones on the road which means the car should slalom in between these cones. If at one point it should turn out the color of the cones is necessary, this won't be a problem. The original color image is always kept, if we want to determine the color of the cone, this can easily be done by looking at the area where the cone is on the original image.

\subsection{Removing redundant information}
The next step is removing everything redundant in the footage. As said before, the images are loaded as grayscale images. Next to that, the images are getting cropped. We're only interested in what is going on below the horizon, everything above it won't give us much information. In the footage we're using, there isn't much to be cropped, because the footage we have is from a camera that was mounted tilted. Now that the sky and everything above the horizon is cropped out, there is one part of preprocessing left.

\subsection{Masking out the ego-car}
The car itself is not moving relative to the camera, as the camera is fixed to the car, so it's irrelevant for the estimation of the movement. A mask is created to erase the car from the footage. This is only done when displaying the image however, otherwise the computation of keypoints wouldn't work properly. When detecting the keypoints in the next step, keypoints laying in the area masked out by the ego-car, can be removed as keypoints. Figure \autoref{fig:input_image} shows an example of a frame before it is preprocessed. Figure \autoref{fig:output_image} shows the image after preprocessing. The black part is the masked out ego-car.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/input_image.jpg}
    \caption{Input image}
    \label{fig:input_image}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/output_image.jpg}
    \caption{Preprocessed image}
    \label{fig:output_image}
\end{figure}