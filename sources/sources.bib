@InProceedings{WesterhoffLessmannMeuterSiegemundKummert2016,
  author    = {Westerhoff, Jens and Lessmann, Stephanie and Meuter, Mirko and Siegemund, Jan and Kummert, Anton},
  booktitle = {2016 IEEE Intelligent Vehicles Symposium (IV)},
  title     = {Development and comparison of homography based estimation techniques for camera to road surface orientation},
  year      = {2016},
  month     = {June},
  pages     = {1034-1040},
  abstract  = {This paper focuses on dynamic orientation estimation of a vehicle-mounted mono camera. In particular, the pitch and roll angles of the camera relative to the road surface. Information about the orientation angles is included in the homography (projective transformation) between two images of a planar road surface. The extraction of angles from a homography matrix is possible but not recommended due to parameter ambiguities. For this reason we do not estimate a full homography matrix but reduce the parameter space to two parameters. In this area of parameter estimation there are mainly two different approaches: The optical flow based approach and the image registration based approach. In order to decide which of these approaches is more favorable for the angle estimation problem, we develop one optical flow based and one image registration based angle estimation algorithm. We are the first directly evaluating and comparing both approaches with each other with the help of an artificial image sequence as well as real-world driving scenarios. In addition, this paper lifts the common limitation of roll angle of zero degree for dynamic camera orientation estimation. Our research finds that there is only a small difference between the parameter estimation results of the optical flow and image registration based approach.},
  doi       = {10.1109/IVS.2016.7535516},
}

@Article{6096039,
  author   = {Scaramuzza, Davide and Fraundorfer, Friedrich},
  journal  = {IEEE Robotics Automation Magazine},
  title    = {Visual Odometry [Tutorial]},
  year     = {2011},
  issn     = {1558-223X},
  month    = {Dec},
  number   = {4},
  pages    = {80-92},
  volume   = {18},
  abstract = {Visual odometry (VO) is the process of estimating the egomotion of an agent (e.g., vehicle, human, and robot) using only the input of a single or If multiple cameras attached to it. Application domains include robotics, wearable computing, augmented reality, and automotive. The term VO was coined in 2004 by Nister in his landmark paper. The term was chosen for its similarity to wheel odometry, which incrementally estimates the motion of a vehicle by integrating the number of turns of its wheels over time. Likewise, VO operates by incrementally estimating the pose of the vehicle through examination of the changes that motion induces on the images of its onboard cameras. For VO to work effectively, there should be sufficient illumination in the environment and a static scene with enough texture to allow apparent motion to be extracted. Furthermore, consecutive frames should be captured by ensuring that they have sufficient scene overlap.},
  doi      = {10.1109/MRA.2011.943233},
}

@Article{6153423,
  author   = {Fraundorfer, Friedrich and Scaramuzza, Davide},
  journal  = {IEEE Robotics Automation Magazine},
  title    = {Visual Odometry : Part II: Matching, Robustness, Optimization, and Applications},
  year     = {2012},
  issn     = {1558-223X},
  month    = {June},
  number   = {2},
  pages    = {78-90},
  volume   = {19},
  abstract = {Part II of the tutorial has summarized the remaining building blocks of the VO pipeline: specifically, how to detect and match salient and repeatable features across frames and robust estimation in the presence of outliers and bundle adjustment. In addition, error propagation, applications, and links to publicly available code are included. VO is a well understood and established part of robotics. VO has reached a maturity that has allowed us to successfully use it for certain classes of applications: space, ground, aerial, and underwater. In the presence of loop closures, VO can be used as a building block for a complete SLAM algorithm to reduce motion drift. Challenges that still remain are to develop and demonstrate large-scale and long-term implementations, such as driving autonomous cars for hundreds of miles. Such systems have recently been demonstrated using Lidar and Radar sensors [86]. However, for VO to be used in such systems, technical issues regarding robustness and, especially, long-term stability have to be resolved. Eventually, VO has the potential to replace Lidar-based systems for egomotion estimation, which are currently leading the state of the art in accuracy, robustness, and reliability. VO offers a cheaper and mechanically easier-to-manufacture solution for egomotion estimation, while, additionally, being fully passive. Furthermore, the ongoing miniaturization of digital cameras offers the possibility to develop smaller and smaller robotic systems capable of ego-motion estimation.},
  doi      = {10.1109/MRA.2012.2182810},
}

@InProceedings{6126544,
    author      = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},  
    booktitle   = {2011 International Conference on Computer Vision},   
    title       = {ORB: An efficient alternative to SIFT or SURF},   
    year        = {2011},  
    volume      = {},  
    number      = {},  
    pages       = {2564-2571},  
    doi         = {10.1109/ICCV.2011.6126544}
}

@book{book,
author = {Trucco, Emanuele and Verri, Alessandro},
year = {1998},
month = {01},
pages = {},
title = {Introductory techniques for 3-D computer vision.},
isbn = {978-0-13-261108-4}
}

@InProceedings{10.1007/11744023_34,
author="Rosten, Edward
and Drummond, Tom",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="Machine Learning for High-Speed Corner Detection",
booktitle="Computer Vision -- ECCV 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="430--443",
abstract="Where feature points are used in real-time frame-rate applications, a high-speed feature detector is necessary. Feature detectors such as SIFT (DoG), Harris and SUSAN are good methods which yield high quality features, however they are too computationally intensive for use in real-time applications of any complexity. Here we show that machine learning can be used to derive a feature detector which can fully process live PAL video using less than 7{\%} of the available processing time. By comparison neither the Harris detector (120{\%}) nor the detection stage of SIFT (300{\%}) can operate at full frame rate.",
isbn="978-3-540-33833-8"
}

@inproceedings{Harris1988ACC,
  title={A Combined Corner and Edge Detector},
  author={Christopher G. Harris and M. J. Stephens},
  booktitle={Alvey Vision Conference},
  year={1988}
}

@article{ROSIN1999291,
title = {Measuring Corner Properties},
journal = {Computer Vision and Image Understanding},
volume = {73},
number = {2},
pages = {291-307},
year = {1999},
issn = {1077-3142},
doi = {https://doi.org/10.1006/cviu.1998.0719},
url = {https://www.sciencedirect.com/science/article/pii/S1077314298907196},
author = {Paul L. Rosin},
abstract = {We describe methods to measure the following properties of gray level corners: subtended angle, orientation, contrast, bluntness (or rounding of the apex), and boundary curvature (for cusps). Unlike most of the published methods for extracting these properties these new methods are relatively simple, efficient, and robust. They rely on the corner being predetected by a standard operator, thus making the measurement problem more tractable. Using 13,000 synthetic images the methods are assessed over a range of conditions: corners of varying orientations and subtended angles, as well as different degrees of noise.}
}

@inbook{unknown-author-2022,
	month = {03},
	title = {{Atan2}},
	url = {https://en.wikipedia.org/wiki/Atan2},
	year = {2022},
}

@InProceedings{10.1007/978-3-642-15561-1_56,
author="Calonder, Michael
and Lepetit, Vincent
and Strecha, Christoph
and Fua, Pascal",
editor="Daniilidis, Kostas
and Maragos, Petros
and Paragios, Nikos",
title="BRIEF: Binary Robust Independent Elementary Features",
booktitle="Computer Vision -- ECCV 2010",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="778--792",
abstract="We propose to use binary strings as an efficient feature point descriptor, which we call BRIEF.We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity difference tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very efficient to compute, instead of the L2 norm as is usually done.",
isbn="978-3-642-15561-1"
}

@inbook{tekalp,
author = {Tekalp, A. and Murat, A.},
year = {1995},
month = {01},
pages = {526},
title = {Digital Video Processing},
volume = {66},
journal = {Journal of Computational and Applied Mathematics - J COMPUT APPL MATH}
}

@book{improc,
author = {Doermann, David and Tombre, Karl},
year = {2014},
month = {01},
pages = {},
title = {Handbook of Document Image Processing and Recognition},
isbn = {978-0-85729-858-4},
journal = {Handbook of Document Image Processing and Recognition},
doi = {10.1007/978-0-85729-859-1}
}

@article{ZHUANG1989175,
title = {A simplification to linear two-view motion algorithms},
journal = {Computer Vision, Graphics, and Image Processing},
volume = {46},
number = {2},
pages = {175-178},
year = {1989},
issn = {0734-189X},
doi = {https://doi.org/10.1016/0734-189X(89)90167-9},
url = {https://www.sciencedirect.com/science/article/pii/0734189X89901679},
author = {Xinhua Zhuang},
abstract = {The note provides a simplification to linear two-view motion algorithms by avoiding the second decomposition of motion parameter matrix E required by all existing linear algorithms.}
}

@article{506592e3b5484e57928e215df49a83cb,
title = "Estimating Three-Dimensional Motion Parameters of a Rigid Planar Patch, II: Singular Value Decomposition",
abstract = "Vis show that the three-dimensional (3-D) motion parameters of a rigid planar patch can be determined by computing the singular value decomposition (SVD) of a 3 X 3 matrix containing the eight so called “pure parameters.” Furthermore, aside from a scale factor for the translation parameters, the number of solutions is either one or two, depending on the multiplicity of the singular values of the matrix.",
author = "Huang, {Thomas S.} and Zhu, {Wei Le} and Zhu, {Wei Le} and Tsai, {Roger Y.} and Zhu, {Wei Le}",
year = "1982",
month = aug,
doi = "10.1109/TASSP.1982.1163931",
language = "English (US)",
volume = "30",
pages = "525--534",
journal = "IRE Transactions on Audio",
issn = "1053-587X",
publisher = "Institute of Electrical and Electronics Engineers Inc.",
number = "4",
}

@article{Huang:86,
author = {T. S. Huang},
journal = {J. Opt. Soc. Am. A},
keywords = {Brightness; Machine vision; Motion analysis; Motion estimation},
number = {9},
pages = {1501--1503},
publisher = {OSA},
title = {Three-dimensional motion analysis by direct matching},
volume = {3},
month = {Sep},
year = {1986},
url = {http://opg.optica.org/josaa/abstract.cfm?URI=josaa-3-9-1501},
doi = {10.1364/JOSAA.3.001501},
abstract = {We describe a direct-matching approach to determining motion of a rigid body from two time-sequential perspective views. The method does not require finding feature correspondences. It is valid under the following assumptions: (1) Brightness constancy---the brightness of an image point corresponding to a fixed object point does not change after motion. (2) The mathematical form of the object surface is known to within a finite number of parameters. We also show how the computation can be simplified in the case of small motion.},
}


@Comment{jabref-meta: databaseType:bibtex;}
